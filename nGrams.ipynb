{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import kenlm\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import util\n",
    "import itertools\n",
    "from helpers import *\n",
    "import sys\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the file\n",
    "with open('count_unigrams.txt','r') as f:\n",
    "    unigram_counts = f.readlines()\n",
    "\n",
    "with open('count_bigrams.txt', 'r') as fb:\n",
    "    bigram_counts = fb.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes in a word and a count and splits it into the word and the integer.\n",
    "ex) parse_word_count('the\\t23135851162\\n') = (the, 23135851162)\n",
    "'''\n",
    "def parse_unigram_count(string):\n",
    "    return (string.split(\"\\t\")[0], int(string.split(\"\\t\")[1].split(\"\\n\")[0]))\n",
    "\n",
    "'''\n",
    "This function takes in 2 words and a count and splits it into the words and the integer.\n",
    "ex) parse_bigram_count ('important area\\t201828\\n') = (important, area, 201828)\n",
    "'''\n",
    "def parse_bigram_count(string):\n",
    "    return (string.split(\"\\t\")[0].split(\" \")[0], string.split(\"\\t\")[0].split(\" \")[1],int(string.split(\"\\t\")[1].split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A dictionary with (word: probability) pairs for 1/3 million most frequent English words \n",
    "unigram_dict = {parse_unigram_count(line)[0]:parse_unigram_count(line)[1] for line in unigram_counts}\n",
    "# A dictionary with (word + word: probability) apirs for 1/4 million most frequent English bigrams\n",
    "bigram_dict = {(parse_bigram_count(line)[0] + \" \" + parse_bigram_count(line)[1]):parse_bigram_count(line)[2] for line in bigram_counts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider a unigram model, where the probability of seeing each word is independent of the words before and after it.\n",
    "P(W1:n)=Î k=1:nP(Wk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a probability distribution dictionary unigram_probs from unigram_dict. But we will examine many, many \"words\" that are not truly words. Our unigram_probs dictionary must return a very small value in that case. (We do not want to simply return 0, because Jane Austen may use her own words (made up words, proper nouns, etc.) that are not in our data set. Instead, following Peter Norvig (CITE), we'll create a class that returns a probability given a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ngram_Prob(dict):\n",
    "    def __init__(self, data, N, fn):\n",
    "        for key,count in data.iteritems():\n",
    "            self[key] = count\n",
    "        self.N = float(N)\n",
    "        self.fn = fn\n",
    "    def __call__(self, key):\n",
    "        if key in self:\n",
    "            return self[key]/self.N\n",
    "        else: \n",
    "            return self.fn(key, self.N)\n",
    "\n",
    "\n",
    "'''\n",
    "This function returns a probailtiy on unrecognized words. \n",
    "It makes it more unlikely for long unrecognized words to be used than short unrecognized words.\n",
    "The probability is inversely proportional to the length of the unrecognized word.\n",
    "'''\n",
    "def avoid_long_words(word, N):\n",
    "    return Decimal(10.)/(Decimal(N) * Decimal(10)**Decimal(len(word)))\n",
    "\n",
    "N = 1024908267229 ## Number of tokens in corpus\n",
    "p_unigram = ngram_Prob(unigram_dict, N, avoid_long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This memoizing function caches the results of previous calls to the segment\n",
    "function so that each results doesn't have to be recomputed.\n",
    "\n",
    "ex) segment(\"helloworld\") doesn't have to compute segment(\"lloworld\") except for once.\n",
    "\n",
    "The memoizing function helps segment only call itself n times, rather than 2^n times.\n",
    "'''\n",
    "def memoize(function):\n",
    "    memo = {}\n",
    "    def helper(x):\n",
    "        if x not in memo.keys():\n",
    "            memo[x] = function(x)\n",
    "        return memo[x]\n",
    "    return helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "    Corpus: The flattened text which we need to segment.\n",
    "Output\n",
    "    A list of words, separated according to our probability model.\n",
    "\n",
    "Ex) segment('helloworld') = ['hello','world']\n",
    "'''\n",
    "\n",
    "@memoize\n",
    "def segment(corpus):\n",
    "    if not corpus: \n",
    "        return []\n",
    "    candidates = tuple([first]+segment(remaining) for first,remaining in splits(corpus))\n",
    "    return max(candidates, key=Pwords)\n",
    "\n",
    "def splits(text, L=20):\n",
    "    '''\n",
    "    Return a list of all possible splits of the text, where length(first word)<=L.\n",
    "    '''\n",
    "#     return [(text[:i+1], text[i+1:]) for i in range(min(len(text), L))]\n",
    "#     return [(text[:i+1], text[i+1:]) for i in range(min(len(text), L))]\n",
    "    return [(text[:i+1], text[i+1:]) for i in range(len(text))]\n",
    "\n",
    "def Pwords(words):\n",
    "    '''\n",
    "    The Naive Bayes probability of a sequence of words.\n",
    "    '''\n",
    "    return product([Decimal(uProb(w)) for w in words])\n",
    "\n",
    "def uProb(word):\n",
    "    '''\n",
    "    Returns the unigram probability of a word by consulting unigram data.\n",
    "    '''\n",
    "    return p_unigram.__call__(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define new functions that use log probability to avoid overflow.\n",
    "from math import log10\n",
    "def log_prob(words):\n",
    "    return sum([log10(uProb(w)) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = alphaLowerNoSpace(\"senseAndSensibilityLast.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brett-This is my iterative version of the recursive function for unigrams only right now. It's working, and it's reasonably fast, but I think there might be a way to speed it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns a dictionary of segments.\n",
    "def bestSplitSmall(string):\n",
    "    docs = splits(string)\n",
    "    docs.reverse()\n",
    "    docs.append((' ', string))\n",
    "    segments = {}\n",
    "    for first, remaining in docs:\n",
    "        if remaining == '':\n",
    "            segments[remaining] = [], Decimal(1.)\n",
    "        else:\n",
    "            rem = splits(remaining)\n",
    "            rem.reverse()\n",
    "            currentScore, bestScore, bestList = Decimal(0.), Decimal(0.), []\n",
    "            for f,r in rem:\n",
    "                currentList = [f] + segments[r][0]\n",
    "                currentScore = Pwords([f]) * segments[r][1]\n",
    "                if currentScore > bestScore: \n",
    "                    bestScore = currentScore\n",
    "                    bestList = currentList\n",
    "            segments[remaining] = bestList, bestScore\n",
    "    return segments[string][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns a dictionary of segments.\n",
    "def segmentStringNew(string):\n",
    "    docs = splits(string)\n",
    "    docs.reverse()\n",
    "    docs.append((' ', string))\n",
    "    docs1 = docs[:20]\n",
    "    docs2 = docs[20:]\n",
    "    segments = {}\n",
    "    for first, remaining in docs1:\n",
    "        if remaining == '':\n",
    "            segments[remaining] = [], Decimal(1.)\n",
    "        else:\n",
    "            rem = splits(remaining)\n",
    "            rem.reverse()\n",
    "#             segments[remaining] = max(([f] + segments[r] for f,r in rem), key=Pwords)\n",
    "            currentScore, bestScore, bestList = Decimal(0.), Decimal(0.), []\n",
    "            for f,r in rem:\n",
    "                currentList = [f] + segments[r][0]\n",
    "                currentScore = Pwords([f]) * segments[r][1]\n",
    "                if currentScore > bestScore: \n",
    "                    bestScore = currentScore\n",
    "                    bestList = currentList\n",
    "            segments[remaining] = bestList, bestScore\n",
    "    \n",
    "    for first, remaining in docs2:\n",
    "        ### Make this a list\n",
    "        mostRecentSegment = segments[remaining[1:]][0]\n",
    "        firstThree = mostRecentSegment[:2]\n",
    "        last = mostRecentSegment[2:]\n",
    "        combinedString = makeString(firstThree)\n",
    "#         splitted = splits(combinedString)\n",
    "#         splitted.reverse()\n",
    "        bestSplit = bestSplitSmall(remaining[0] + combinedString)\n",
    "#         print \"last: \", last\n",
    "        stitched = bestSplit + last\n",
    "        segments[remaining] = (stitched, Decimal(1.))\n",
    "\n",
    "    return segments[string][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 1 Âµs, total: 3 Âµs\n",
      "Wall time: 5.96 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# segmentStringNew(doc[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a probability dictionary out of our bigram_counts dictionary called `p_bigram`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1024908267229 is the number of tokens in the corpus\n",
    "p_bigram = ngram_Prob(bigram_dict, 1024908267229, avoid_long_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a function `cond_prob` which returns P(word | previous_word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def cond_prob(word, prev):\n",
    "    \"The conditional probability P(word | previous-word).\" \n",
    "    try:\n",
    "        return Decimal(p_bigram[prev + ' ' + word]/float(p_unigram[prev]))\n",
    "    # If the bigram is not documented in the top 1/4 million English bigrams, just return unigram(word).\n",
    "    except KeyError:\n",
    "        return Decimal(p_unigram(word))\n",
    "\n",
    "def memoize2(function):\n",
    "    memo = {}\n",
    "    def helper(x,y):\n",
    "        if (x,y) not in memo.keys():\n",
    "            memo[(x,y)] = function(x,y)\n",
    "        return memo[(x,y)]\n",
    "    return helper\n",
    "\n",
    "@memoize2\n",
    "def segment2(text, prev='<S>'):\n",
    "    \"Return (log P(words), words), where words is the best segmentation.\"\n",
    "    if not text: return 0.0, []\n",
    "    candidates = [combine(log10(cond_prob(first, prev)), first, segment2(rem, first)) for first,rem in splits(text)]\n",
    "    return max(candidates)\n",
    "                                                            \n",
    "def combine(Pfirst, first, (Prem, rem)):\n",
    "    \"Combine first and rem results into one (probability, words) pair.\"\n",
    "    # We add here because we're dealing with the logs\n",
    "    return Pfirst+Prem, [first]+rem    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigramSegmentStringSmall(string):\n",
    "    docs = splits(string)\n",
    "    segments = {}\n",
    "    for first, remaining in docs:\n",
    "        segments['']=[''],Decimal(1.)\n",
    "        fir = splits(first)\n",
    "        currentScore, bestScore, bestList = Decimal(0.), Decimal(0.), []\n",
    "        for f,r in fir:\n",
    "            currentList = segments[f[:-1]][0] + [f[-1]+r]\n",
    "            currentScore = cond_prob(f[-1]+r,segments[f[:-1]][0][-1]) * segments[f[:-1]][1]\n",
    "            if currentScore > bestScore:\n",
    "                bestScore = currentScore\n",
    "                bestList = currentList\n",
    "        segments[first] = bestList, bestScore\n",
    "    return segments[string][0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'in', 'rome', 'do', 'as', 'the', 'romans', 'do']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramSegmentStringSmall('wheninromedoastheromansdo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigramSegmentString(string):\n",
    "    docs = splits(string)\n",
    "    docs1 = docs[:20]\n",
    "    docs2 = docs[20:]\n",
    "    segments = {}\n",
    "    for first, remaining in docs1:\n",
    "        segments['']= [''], Decimal(1.)\n",
    "        fir = splits(first)\n",
    "        currentScore, bestScore, bestList = Decimal(0.), Decimal(0.), []\n",
    "        for f,r in fir:\n",
    "            currentList = segments[f[:-1]][0] + [f[-1]+r]\n",
    "            # Last thing is the prior\n",
    "            currentScore = cond_prob(f[-1]+r, segments[f[:-1]][0][-1]) * segments[f[:-1]][1]\n",
    "            if currentScore > bestScore:\n",
    "                bestScore = currentScore\n",
    "                bestList = currentList\n",
    "        segments[first] = bestList, bestScore\n",
    "        \n",
    "    for first, remaining in docs2:\n",
    "        ### Make this a list\n",
    "        mostRecentSegment = segments[first[:-1]][0]\n",
    "        closestThree = mostRecentSegment[-3:]\n",
    "        furthestThree = mostRecentSegment[:-3]\n",
    "        combinedString = makeString(closestThree)\n",
    "        bestSplit = bestSplitSmall(combinedString + first[-1])\n",
    "        stitched = furthestThree + bestSplit\n",
    "        segments[first] = (stitched, Decimal(1.))\n",
    "    return segments[string][0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 2.04 s, total: 1min 53s\n",
      "Wall time: 1min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['after',\n",
       " 'a',\n",
       " 'proper',\n",
       " 'resistance',\n",
       " 'on',\n",
       " 'the',\n",
       " 'part',\n",
       " 'of',\n",
       " 'mrs',\n",
       " 'ferrars',\n",
       " 'just',\n",
       " 'so',\n",
       " 'violent',\n",
       " 'and',\n",
       " 'so',\n",
       " 'steady',\n",
       " 'as',\n",
       " 'to',\n",
       " 'preserve',\n",
       " 'her',\n",
       " 'from',\n",
       " 'that',\n",
       " 'reproach',\n",
       " 'which',\n",
       " 'she',\n",
       " 'always',\n",
       " 'seemed',\n",
       " 'fearful',\n",
       " 'of',\n",
       " 'incurring',\n",
       " 'the',\n",
       " 'reproach',\n",
       " 'of',\n",
       " 'being',\n",
       " 'too',\n",
       " 'amiable',\n",
       " 'edward',\n",
       " 'was',\n",
       " 'admitted',\n",
       " 'to',\n",
       " 'her',\n",
       " 'presence',\n",
       " 'and',\n",
       " 'pronounced',\n",
       " 'to',\n",
       " 'be',\n",
       " 'again',\n",
       " 'her',\n",
       " 'son',\n",
       " 'her',\n",
       " 'family',\n",
       " 'had',\n",
       " 'of',\n",
       " 'late',\n",
       " 'been',\n",
       " 'exceedingly',\n",
       " 'fluctuating',\n",
       " 'for',\n",
       " 'many',\n",
       " 'years',\n",
       " 'of',\n",
       " 'her',\n",
       " 'life',\n",
       " 'she',\n",
       " 'had',\n",
       " 'had',\n",
       " 'two',\n",
       " 'sons',\n",
       " 'but',\n",
       " 'the',\n",
       " 'crime',\n",
       " 'and',\n",
       " 'annihilation',\n",
       " 'of',\n",
       " 'edward',\n",
       " 'a',\n",
       " 'few',\n",
       " 'weeks',\n",
       " 'ago',\n",
       " 'had',\n",
       " 'robbed',\n",
       " 'her',\n",
       " 'of',\n",
       " 'one',\n",
       " 'the',\n",
       " 'similar',\n",
       " 'annihilation',\n",
       " 'of',\n",
       " 'robert',\n",
       " 'had',\n",
       " 'left',\n",
       " 'her',\n",
       " 'for',\n",
       " 'a',\n",
       " 'fortnight',\n",
       " 'without',\n",
       " 'any',\n",
       " 'and',\n",
       " 'now',\n",
       " 'by',\n",
       " 'the',\n",
       " 'resuscitation',\n",
       " 'of',\n",
       " 'edwards',\n",
       " 'he',\n",
       " 'had',\n",
       " 'one',\n",
       " 'again',\n",
       " 'inspite',\n",
       " 'of',\n",
       " 'his',\n",
       " 'being',\n",
       " 'allowed',\n",
       " 'once',\n",
       " 'more',\n",
       " 'to',\n",
       " 'live',\n",
       " 'however',\n",
       " 'he',\n",
       " 'did',\n",
       " 'not',\n",
       " 'feel',\n",
       " 'the',\n",
       " 'continuance',\n",
       " 'of',\n",
       " 'his',\n",
       " 'existence',\n",
       " 'secure',\n",
       " 'till',\n",
       " 'he',\n",
       " 'had',\n",
       " 'revealed',\n",
       " 'his',\n",
       " 'present',\n",
       " 'engagement',\n",
       " 'for',\n",
       " 'the',\n",
       " 'publication',\n",
       " 'of',\n",
       " 'that',\n",
       " 'circumstance',\n",
       " 'he',\n",
       " 'feared',\n",
       " 'might',\n",
       " 'give',\n",
       " 'a',\n",
       " 'sudden',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'his',\n",
       " 'constitution',\n",
       " 'and',\n",
       " 'carry',\n",
       " 'him',\n",
       " 'off',\n",
       " 'as',\n",
       " 'rapidly',\n",
       " 'as',\n",
       " 'before',\n",
       " 'with',\n",
       " 'apprehensive',\n",
       " 'caution',\n",
       " 'therefore',\n",
       " 'it',\n",
       " 'was',\n",
       " 'revealed',\n",
       " 'and',\n",
       " 'he',\n",
       " 'was',\n",
       " 'listened',\n",
       " 'to',\n",
       " 'with',\n",
       " 'unexpected',\n",
       " 'calmness',\n",
       " 'mrs',\n",
       " 'ferrars',\n",
       " 'at',\n",
       " 'first',\n",
       " 'reasonably',\n",
       " 'endeavoured',\n",
       " 'to',\n",
       " 'dissuade',\n",
       " 'him',\n",
       " 'from',\n",
       " 'marrying',\n",
       " 'miss',\n",
       " 'dashwood',\n",
       " 'by',\n",
       " 'every',\n",
       " 'argument',\n",
       " 'in',\n",
       " 'her',\n",
       " 'power',\n",
       " 'told',\n",
       " 'him',\n",
       " 'that',\n",
       " 'in',\n",
       " 'miss',\n",
       " 'morton',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'a',\n",
       " 'woman',\n",
       " 'of',\n",
       " 'higher',\n",
       " 'rank',\n",
       " 'and',\n",
       " 'larger',\n",
       " 'fortune',\n",
       " 'and',\n",
       " 'enforced',\n",
       " 'the',\n",
       " 'assertion',\n",
       " 'by',\n",
       " 'observing',\n",
       " 'that',\n",
       " 'miss',\n",
       " 'morton',\n",
       " 'was',\n",
       " 'the',\n",
       " 'daughter',\n",
       " 'of',\n",
       " 'a',\n",
       " 'nobleman',\n",
       " 'with',\n",
       " 'thirty',\n",
       " 'thousand',\n",
       " 'pounds',\n",
       " 'while',\n",
       " 'miss',\n",
       " 'dashwood',\n",
       " 'was',\n",
       " 'only',\n",
       " 'the',\n",
       " 'daughter',\n",
       " 'of',\n",
       " 'a',\n",
       " 'private',\n",
       " 'gentleman',\n",
       " 'with',\n",
       " 'no',\n",
       " 'more',\n",
       " 'than',\n",
       " 'three',\n",
       " 'but',\n",
       " 'when',\n",
       " 'she',\n",
       " 'found',\n",
       " 'that',\n",
       " 'though',\n",
       " 'perfectly',\n",
       " 'admitting',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'of',\n",
       " 'her',\n",
       " 'representation',\n",
       " 'he',\n",
       " 'was',\n",
       " 'by',\n",
       " 'no',\n",
       " 'means',\n",
       " 'inclined',\n",
       " 'to',\n",
       " 'be',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'it',\n",
       " 'she',\n",
       " 'judged',\n",
       " 'it',\n",
       " 'wisest',\n",
       " 'from',\n",
       " 'the',\n",
       " 'experience',\n",
       " 'of',\n",
       " 'the',\n",
       " 'past',\n",
       " 'to',\n",
       " 'submit',\n",
       " 'and',\n",
       " 'therefore',\n",
       " 'after',\n",
       " 'such',\n",
       " 'an',\n",
       " 'ungracious',\n",
       " 'delay',\n",
       " 'as',\n",
       " 'she',\n",
       " 'owed',\n",
       " 'to',\n",
       " 'her',\n",
       " 'own',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'as',\n",
       " 'served',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'every',\n",
       " 'suspicion',\n",
       " 'of',\n",
       " 'goodwill',\n",
       " 'she',\n",
       " 'issued',\n",
       " 'her',\n",
       " 'decree',\n",
       " 'of',\n",
       " 'consent',\n",
       " 'to',\n",
       " 'the',\n",
       " 'marriage',\n",
       " 'of',\n",
       " 'edward',\n",
       " 'and',\n",
       " 'elinor',\n",
       " 'what',\n",
       " 'she',\n",
       " 'would',\n",
       " 'engage',\n",
       " 'to',\n",
       " 'do',\n",
       " 'towards',\n",
       " 'augmenting',\n",
       " 'their',\n",
       " 'income',\n",
       " 'was',\n",
       " 'next',\n",
       " 'to',\n",
       " 'be',\n",
       " 'considered',\n",
       " 'and',\n",
       " 'here',\n",
       " 'it',\n",
       " 'plainly',\n",
       " 'appeared',\n",
       " 'that',\n",
       " 'though',\n",
       " 'edward',\n",
       " 'was',\n",
       " 'now',\n",
       " 'her',\n",
       " 'only',\n",
       " 'son',\n",
       " 'he',\n",
       " 'was',\n",
       " 'by',\n",
       " 'no',\n",
       " 'means',\n",
       " 'her',\n",
       " 'eldest',\n",
       " 'for',\n",
       " 'while',\n",
       " 'robert',\n",
       " 'was',\n",
       " 'inevitably',\n",
       " 'endowed',\n",
       " 'with',\n",
       " 'a',\n",
       " 'thousand',\n",
       " 'pounds',\n",
       " 'a',\n",
       " 'year',\n",
       " 'not',\n",
       " 'the',\n",
       " 'smallest',\n",
       " 'objection',\n",
       " 'was',\n",
       " 'made',\n",
       " 'against',\n",
       " 'edwards',\n",
       " 'taking',\n",
       " 'orders',\n",
       " 'for',\n",
       " 'the',\n",
       " 'sake',\n",
       " 'of',\n",
       " 'two',\n",
       " 'hundred',\n",
       " 'and',\n",
       " 'fifty',\n",
       " 'at',\n",
       " 'the',\n",
       " 'utmost',\n",
       " 'nor',\n",
       " 'was',\n",
       " 'anything',\n",
       " 'promised',\n",
       " 'either',\n",
       " 'for',\n",
       " 'the',\n",
       " 'present',\n",
       " 'or',\n",
       " 'in',\n",
       " 'future',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'ten',\n",
       " 'thousand',\n",
       " 'pounds',\n",
       " 'which',\n",
       " 'had',\n",
       " 'been',\n",
       " 'given',\n",
       " 'with',\n",
       " 'fanny',\n",
       " 'it',\n",
       " 'was',\n",
       " 'as',\n",
       " 'much',\n",
       " 'however',\n",
       " 'as',\n",
       " 'was',\n",
       " 'desired',\n",
       " 'and',\n",
       " 'more',\n",
       " 'than',\n",
       " 'was',\n",
       " 'expected',\n",
       " 'by',\n",
       " 'edward',\n",
       " 'and',\n",
       " 'elinor',\n",
       " 'and',\n",
       " 'mrs',\n",
       " 'ferrars',\n",
       " 'herself',\n",
       " 'by',\n",
       " 'her',\n",
       " 'shuffling',\n",
       " 'excuses',\n",
       " 'seemed',\n",
       " 'the',\n",
       " 'only',\n",
       " 'person',\n",
       " 'surprised',\n",
       " 'at',\n",
       " 'her',\n",
       " 'not',\n",
       " 'giving',\n",
       " 'more',\n",
       " 'with',\n",
       " 'an',\n",
       " 'income',\n",
       " 'quite',\n",
       " 'sufficient',\n",
       " 'to',\n",
       " 'their',\n",
       " 'wants',\n",
       " 'thus',\n",
       " 'secured',\n",
       " 'to',\n",
       " 'them',\n",
       " 'they',\n",
       " 'had',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'wait',\n",
       " 'for',\n",
       " 'after',\n",
       " 'edward',\n",
       " 'was',\n",
       " 'in',\n",
       " 'possession',\n",
       " 'of',\n",
       " 'the',\n",
       " 'living',\n",
       " 'but',\n",
       " 'the',\n",
       " 'readiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'house',\n",
       " 'to',\n",
       " 'which',\n",
       " 'colonel',\n",
       " 'brandon',\n",
       " 'with',\n",
       " 'an',\n",
       " 'eager',\n",
       " 'desire',\n",
       " 'for',\n",
       " 'the',\n",
       " 'accommodation',\n",
       " 'of',\n",
       " 'elinor',\n",
       " 'was',\n",
       " 'making',\n",
       " 'considerable',\n",
       " 'improvements',\n",
       " 'and',\n",
       " 'after',\n",
       " 'waiting',\n",
       " 'sometime',\n",
       " 'for',\n",
       " 'their',\n",
       " 'completion',\n",
       " 'after',\n",
       " 'experiencing',\n",
       " 'as',\n",
       " 'usual',\n",
       " 'a',\n",
       " 'thousand',\n",
       " 'disappointments',\n",
       " 'and',\n",
       " 'delays',\n",
       " 'from',\n",
       " 'the',\n",
       " 'unaccountable',\n",
       " 'dilator',\n",
       " 'iness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'workmen',\n",
       " 'elinor',\n",
       " 'as',\n",
       " 'usual',\n",
       " 'broke',\n",
       " 'through',\n",
       " 'the',\n",
       " 'first',\n",
       " 'positive',\n",
       " 'resolution',\n",
       " 'of',\n",
       " 'not',\n",
       " 'marrying',\n",
       " 'till',\n",
       " 'everything',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ceremony',\n",
       " 'took',\n",
       " 'place',\n",
       " 'in',\n",
       " 'barton',\n",
       " 'church',\n",
       " 'early',\n",
       " 'in',\n",
       " 'the',\n",
       " 'autumn',\n",
       " 'the',\n",
       " 'first',\n",
       " 'month',\n",
       " 'after',\n",
       " 'their',\n",
       " 'marriage',\n",
       " 'was',\n",
       " 'spent',\n",
       " 'with',\n",
       " 'their',\n",
       " 'friend',\n",
       " 'at',\n",
       " 'the',\n",
       " 'mansion',\n",
       " 'house',\n",
       " 'from',\n",
       " 'whence',\n",
       " 'they',\n",
       " 'could',\n",
       " 'superintend',\n",
       " 'the',\n",
       " 'progress',\n",
       " 'of',\n",
       " 'the',\n",
       " 'parsonage',\n",
       " 'and',\n",
       " 'direct',\n",
       " 'everything',\n",
       " 'as',\n",
       " 'they',\n",
       " 'liked',\n",
       " 'on',\n",
       " 'the',\n",
       " 'spot',\n",
       " 'could',\n",
       " 'choose',\n",
       " 'papers',\n",
       " 'projects',\n",
       " 'h',\n",
       " 'rubber',\n",
       " 'ies',\n",
       " 'and',\n",
       " 'invent',\n",
       " 'a',\n",
       " 'sweep',\n",
       " 'mrs',\n",
       " 'jennings',\n",
       " 's',\n",
       " 'prophecies',\n",
       " 'though',\n",
       " 'rather',\n",
       " 'jumbled',\n",
       " 'together',\n",
       " 'were',\n",
       " 'chiefly',\n",
       " 'fulfilled',\n",
       " 'for',\n",
       " 'she',\n",
       " 'was',\n",
       " 'able',\n",
       " 'to',\n",
       " 'visit',\n",
       " 'edward',\n",
       " 'and',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'in',\n",
       " 'their',\n",
       " 'parsonage',\n",
       " 'by',\n",
       " 'michaelmas',\n",
       " 'and',\n",
       " 'she',\n",
       " 'found',\n",
       " 'in',\n",
       " 'elinor',\n",
       " 'and',\n",
       " 'her',\n",
       " 'husband',\n",
       " 'as',\n",
       " 'she',\n",
       " 'really',\n",
       " 'believed',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'happiest',\n",
       " 'couples',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'they',\n",
       " 'had',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'wish',\n",
       " 'for',\n",
       " 'but',\n",
       " 'the',\n",
       " 'marriage',\n",
       " 'of',\n",
       " 'colonel',\n",
       " 'brandon',\n",
       " 'and',\n",
       " 'marianne',\n",
       " 'and',\n",
       " 'rather',\n",
       " 'better',\n",
       " 'pasturage',\n",
       " 'for',\n",
       " 'their',\n",
       " 'cows',\n",
       " 'they',\n",
       " 'were',\n",
       " 'visited',\n",
       " 'on',\n",
       " 'their',\n",
       " 'first',\n",
       " 'settling',\n",
       " 'by',\n",
       " 'almost',\n",
       " 'all',\n",
       " 'their',\n",
       " 'relations',\n",
       " 'and',\n",
       " 'friends',\n",
       " 'mrs',\n",
       " 'ferrars',\n",
       " 'came',\n",
       " 'to',\n",
       " 'inspect',\n",
       " 'the',\n",
       " 'happiness',\n",
       " 'which',\n",
       " 'she',\n",
       " 'was',\n",
       " 'almost',\n",
       " 'ashamed',\n",
       " 'of',\n",
       " 'having',\n",
       " 'authorised',\n",
       " 'and',\n",
       " 'even',\n",
       " 'the',\n",
       " 'dash',\n",
       " 'woods',\n",
       " 'were',\n",
       " 'at',\n",
       " 'the',\n",
       " 'expense',\n",
       " 'of',\n",
       " 'a',\n",
       " 'journey',\n",
       " 'from',\n",
       " 'sussex',\n",
       " 'to',\n",
       " 'do',\n",
       " 'them',\n",
       " 'honour',\n",
       " 'i',\n",
       " 'will',\n",
       " 'not',\n",
       " 'say',\n",
       " 'that',\n",
       " 'i',\n",
       " 'am',\n",
       " 'disappointed',\n",
       " 'my',\n",
       " 'dear',\n",
       " 'sister',\n",
       " 'said',\n",
       " 'john',\n",
       " 'as',\n",
       " 'they',\n",
       " 'were',\n",
       " 'walking',\n",
       " 'together',\n",
       " 'one',\n",
       " 'morning',\n",
       " 'before',\n",
       " 'the',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'del',\n",
       " 'a',\n",
       " 'ford',\n",
       " 'house',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'saying',\n",
       " 'too',\n",
       " 'much',\n",
       " 'for',\n",
       " 'certainly',\n",
       " 'you',\n",
       " 'have',\n",
       " 'been',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'fortunate',\n",
       " 'young',\n",
       " 'women',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'as',\n",
       " 'it',\n",
       " 'is',\n",
       " 'but',\n",
       " 'i',\n",
       " 'confess',\n",
       " 'it',\n",
       " 'would',\n",
       " 'give',\n",
       " 'me',\n",
       " 'great',\n",
       " 'pleasure',\n",
       " 'to',\n",
       " 'call',\n",
       " 'colonel',\n",
       " 'brandon',\n",
       " 'brother',\n",
       " 'his',\n",
       " 'property',\n",
       " 'here',\n",
       " 'his',\n",
       " 'place',\n",
       " 'his',\n",
       " 'house',\n",
       " 'everything',\n",
       " 'is',\n",
       " 'in',\n",
       " 'such',\n",
       " 'respectable',\n",
       " 'and',\n",
       " 'excellent',\n",
       " 'condition',\n",
       " 'and',\n",
       " 'his',\n",
       " 'woods',\n",
       " 'i',\n",
       " 'have',\n",
       " 'not',\n",
       " 'seen',\n",
       " 'such',\n",
       " 'timber',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'dorsetshire',\n",
       " 'as',\n",
       " 'there',\n",
       " 'is',\n",
       " 'now',\n",
       " 'standing',\n",
       " 'in',\n",
       " 'del',\n",
       " 'a',\n",
       " 'ford',\n",
       " 'hanger',\n",
       " 'and',\n",
       " 'though',\n",
       " 'perhaps',\n",
       " 'marianne',\n",
       " 'may',\n",
       " 'not',\n",
       " 'seem',\n",
       " 'exactly',\n",
       " 'the',\n",
       " 'person',\n",
       " 'to',\n",
       " 'attract',\n",
       " 'him',\n",
       " 'yeti',\n",
       " 'think',\n",
       " 'it',\n",
       " 'would',\n",
       " 'altogether',\n",
       " 'be',\n",
       " 'advisable',\n",
       " 'for',\n",
       " 'you',\n",
       " 'to',\n",
       " 'have',\n",
       " 'them',\n",
       " 'now',\n",
       " 'frequently',\n",
       " 'staying',\n",
       " 'with',\n",
       " 'you',\n",
       " 'for',\n",
       " 'as',\n",
       " 'colonel',\n",
       " 'brandon',\n",
       " 'seems',\n",
       " 'a',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'at',\n",
       " 'home',\n",
       " 'nobody',\n",
       " 'can',\n",
       " 'tell',\n",
       " 'what',\n",
       " 'may',\n",
       " 'happen',\n",
       " 'for',\n",
       " 'when',\n",
       " 'people',\n",
       " 'are',\n",
       " 'much',\n",
       " 'thrown',\n",
       " 'together',\n",
       " 'and',\n",
       " 'see',\n",
       " 'little',\n",
       " 'of',\n",
       " 'anybody',\n",
       " 'else',\n",
       " 'and',\n",
       " 'it',\n",
       " 'will',\n",
       " 'always',\n",
       " 'be',\n",
       " 'in',\n",
       " 'your',\n",
       " 'power',\n",
       " 'to',\n",
       " 'set',\n",
       " 'her',\n",
       " 'off',\n",
       " 'to',\n",
       " 'advantage',\n",
       " 'and',\n",
       " 'so',\n",
       " 'forth',\n",
       " 'in',\n",
       " 'short',\n",
       " 'you',\n",
       " 'may',\n",
       " 'as',\n",
       " 'well',\n",
       " 'give',\n",
       " 'her',\n",
       " 'a',\n",
       " 'chance',\n",
       " 'you',\n",
       " 'understand',\n",
       " 'me',\n",
       " 'but',\n",
       " 'though',\n",
       " 'mrs',\n",
       " 'ferrars',\n",
       " 'did',\n",
       " 'come',\n",
       " 'to',\n",
       " 'see',\n",
       " 'them',\n",
       " 'and',\n",
       " 'always',\n",
       " 'treated',\n",
       " 'them',\n",
       " 'with',\n",
       " 'the',\n",
       " 'make',\n",
       " 'believe',\n",
       " 'of',\n",
       " 'decent',\n",
       " 'affection',\n",
       " 'they',\n",
       " 'were',\n",
       " 'never',\n",
       " 'insulted',\n",
       " 'by',\n",
       " 'her',\n",
       " 'real',\n",
       " 'favour',\n",
       " 'and',\n",
       " 'preference',\n",
       " 'that',\n",
       " 'was',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'folly',\n",
       " 'of',\n",
       " 'robert',\n",
       " 'and',\n",
       " 'the',\n",
       " 'cunning',\n",
       " 'of',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'earned',\n",
       " 'by',\n",
       " 'them',\n",
       " 'before',\n",
       " 'many',\n",
       " 'months',\n",
       " 'had',\n",
       " 'passed',\n",
       " 'away',\n",
       " 'the',\n",
       " 'selfish',\n",
       " 'sagacity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'which',\n",
       " 'had',\n",
       " 'at',\n",
       " 'first',\n",
       " 'drawn',\n",
       " 'robert',\n",
       " 'into',\n",
       " 'the',\n",
       " 'scrape',\n",
       " 'was',\n",
       " 'the',\n",
       " 'principal',\n",
       " 'instrument',\n",
       " 'of',\n",
       " 'his',\n",
       " 'deliverance',\n",
       " 'from',\n",
       " 'it',\n",
       " 'for',\n",
       " 'her',\n",
       " 'respectful',\n",
       " 'humility',\n",
       " 'assiduous',\n",
       " 'attentions',\n",
       " 'and',\n",
       " 'endless',\n",
       " 'flatteries',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'the',\n",
       " 'smallest',\n",
       " 'opening',\n",
       " 'was',\n",
       " 'given',\n",
       " 'for',\n",
       " 'their',\n",
       " 'exercise',\n",
       " 'reconciled',\n",
       " 'mrs',\n",
       " 'ferrars',\n",
       " 'to',\n",
       " ...]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bigramSegmentString(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
